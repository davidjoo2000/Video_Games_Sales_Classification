{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import mean_absolute_error,accuracy_score,classification_report,precision_recall_fscore_support, confusion_matrix,r2_score,mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>Critic_Count</th>\n",
       "      <th>User_Score</th>\n",
       "      <th>User_Count</th>\n",
       "      <th>Developer</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wii Sports</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>41.36</td>\n",
       "      <td>28.96</td>\n",
       "      <td>3.77</td>\n",
       "      <td>8.45</td>\n",
       "      <td>82.53</td>\n",
       "      <td>76.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Super Mario Bros.</td>\n",
       "      <td>NES</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>Platform</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>29.08</td>\n",
       "      <td>3.58</td>\n",
       "      <td>6.81</td>\n",
       "      <td>0.77</td>\n",
       "      <td>40.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mario Kart Wii</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Racing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.68</td>\n",
       "      <td>12.76</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.29</td>\n",
       "      <td>35.52</td>\n",
       "      <td>82.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>709.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wii Sports Resort</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.61</td>\n",
       "      <td>10.93</td>\n",
       "      <td>3.28</td>\n",
       "      <td>2.95</td>\n",
       "      <td>32.77</td>\n",
       "      <td>80.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pokemon Red/Pokemon Blue</td>\n",
       "      <td>GB</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>Role-Playing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>11.27</td>\n",
       "      <td>8.89</td>\n",
       "      <td>10.22</td>\n",
       "      <td>1.00</td>\n",
       "      <td>31.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Name Platform  Year_of_Release         Genre Publisher  \\\n",
       "0                Wii Sports      Wii           2006.0        Sports  Nintendo   \n",
       "1         Super Mario Bros.      NES           1985.0      Platform  Nintendo   \n",
       "2            Mario Kart Wii      Wii           2008.0        Racing  Nintendo   \n",
       "3         Wii Sports Resort      Wii           2009.0        Sports  Nintendo   \n",
       "4  Pokemon Red/Pokemon Blue       GB           1996.0  Role-Playing  Nintendo   \n",
       "\n",
       "   NA_Sales  EU_Sales  JP_Sales  Other_Sales  Global_Sales  Critic_Score  \\\n",
       "0     41.36     28.96      3.77         8.45         82.53          76.0   \n",
       "1     29.08      3.58      6.81         0.77         40.24           NaN   \n",
       "2     15.68     12.76      3.79         3.29         35.52          82.0   \n",
       "3     15.61     10.93      3.28         2.95         32.77          80.0   \n",
       "4     11.27      8.89     10.22         1.00         31.37           NaN   \n",
       "\n",
       "   Critic_Count  User_Score  User_Count Developer Rating  \n",
       "0          51.0         8.0       322.0  Nintendo      E  \n",
       "1           NaN         NaN         NaN       NaN    NaN  \n",
       "2          73.0         8.3       709.0  Nintendo      E  \n",
       "3          73.0         8.0       192.0  Nintendo      E  \n",
       "4           NaN         NaN         NaN       NaN    NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Video_Games_Sales_as_at_22_Dec_2016.csv')\n",
    "data.head()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)  \n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Year_of_Release', 'NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales',\n",
      "       'Global_Sales', 'Critic_Score', 'Critic_Count', 'User_Score',\n",
      "       'User_Count'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "numerical_columns = data.select_dtypes('float64').columns\n",
    "categorical_columns = data.select_dtypes('object').columns\n",
    "print(numerical_columns)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Üresek eltávolítása"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_replace = ['Publisher', 'Developer','Name']\n",
    "for column in cols_to_replace:\n",
    "    data[column].fillna('Unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regi jatekok altalaban nem ertekeltek\n",
    "data['Critic_Count'] = data['Critic_Count'].fillna(1)\n",
    "data['User_Count'] = data['User_Count'].fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "columns_with_missing = ['User_Score', 'Critic_Score','Year_of_Release']\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "data[columns_with_missing] = imputer.fit_transform(data[columns_with_missing])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lehet hogy nagyon rossz ötlet\n",
    "#helyette\n",
    "#data.dropna(subset=['Genre'], inplace=True)\n",
    "for index, row in data.iterrows():\n",
    "    year = row['Year_of_Release']\n",
    "    genre = row['Genre']\n",
    "    if pd.isnull(row['Rating']):\n",
    "        if year >= 2010 and genre in ['Action', 'Adventure']:\n",
    "            data.at[index, 'Rating'] = 'T'\n",
    "        elif year < 2010 and genre in ['Action', 'Adventure']:\n",
    "            data.at[index, 'Rating'] = 'M'\n",
    "        elif genre in ['Sports', 'Racing']:\n",
    "            data.at[index, 'Rating'] = 'E'\n",
    "        else:\n",
    "            data.at[index, 'Rating'] = 'E10+'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(subset=['Genre'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.isnull().sum())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['Year_of_Release'] = data['Year_of_Release'].astype(int)\n",
    "data['User_Count'] = data['User_Count'].astype(int)\n",
    "data['Critic_Count'] = data['Critic_Count'].astype(int)\n",
    "data['Critic_Score'] = data['Critic_Score'].astype(int)\n",
    "\n",
    "data['User_Score'] = (data['User_Score'] * 10).astype(int)\n",
    "\n",
    "columns_to_convert = ['NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales', 'Global_Sales']\n",
    "data[columns_to_convert] = (data[columns_to_convert] * 100).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>Critic_Count</th>\n",
       "      <th>User_Score</th>\n",
       "      <th>User_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006</td>\n",
       "      <td>4136</td>\n",
       "      <td>2896</td>\n",
       "      <td>377</td>\n",
       "      <td>844</td>\n",
       "      <td>8253</td>\n",
       "      <td>76</td>\n",
       "      <td>51</td>\n",
       "      <td>80</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1985</td>\n",
       "      <td>2908</td>\n",
       "      <td>358</td>\n",
       "      <td>681</td>\n",
       "      <td>77</td>\n",
       "      <td>4024</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008</td>\n",
       "      <td>1568</td>\n",
       "      <td>1276</td>\n",
       "      <td>379</td>\n",
       "      <td>329</td>\n",
       "      <td>3552</td>\n",
       "      <td>82</td>\n",
       "      <td>73</td>\n",
       "      <td>83</td>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>1561</td>\n",
       "      <td>1093</td>\n",
       "      <td>328</td>\n",
       "      <td>295</td>\n",
       "      <td>3277</td>\n",
       "      <td>80</td>\n",
       "      <td>73</td>\n",
       "      <td>80</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1996</td>\n",
       "      <td>1127</td>\n",
       "      <td>889</td>\n",
       "      <td>1022</td>\n",
       "      <td>100</td>\n",
       "      <td>3137</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16714</th>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16715</th>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16716</th>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16717</th>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16718</th>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16717 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year_of_Release  NA_Sales  EU_Sales  JP_Sales  Other_Sales  \\\n",
       "0                 2006      4136      2896       377          844   \n",
       "1                 1985      2908       358       681           77   \n",
       "2                 2008      1568      1276       379          329   \n",
       "3                 2009      1561      1093       328          295   \n",
       "4                 1996      1127       889      1022          100   \n",
       "...                ...       ...       ...       ...          ...   \n",
       "16714             2016         0         0         1            0   \n",
       "16715             2006         0         1         0            0   \n",
       "16716             2016         0         0         1            0   \n",
       "16717             2003         1         0         0            0   \n",
       "16718             2016         0         0         1            0   \n",
       "\n",
       "       Global_Sales  Critic_Score  Critic_Count  User_Score  User_Count  \n",
       "0              8253            76            51          80         322  \n",
       "1              4024            73             1          59           1  \n",
       "2              3552            82            73          83         709  \n",
       "3              3277            80            73          80         192  \n",
       "4              3137            91             1          84           1  \n",
       "...             ...           ...           ...         ...         ...  \n",
       "16714             1            78             1          75           1  \n",
       "16715             1            67             1          78           1  \n",
       "16716             1            78             1          75           1  \n",
       "16717             1            77             1          74           1  \n",
       "16718             1            78             1          75           1  \n",
       "\n",
       "[16717 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[numerical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_counts = data['Genre'].value_counts()\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(genre_counts.index, genre_counts.values)\n",
    "plt.xlabel('Genre')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Number of Games per Genre')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Name nem kell mert egyéni érték \n",
    "data = data.drop(['Name'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = data.select_dtypes('int32').columns\n",
    "categorical_columns = data.select_dtypes('object').columns\n",
    "print(numerical_columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LabelEncoding, normalization, splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label_encoders = {}\n",
    "\n",
    "for column in categorical_columns:\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    encoded_values = label_encoder.fit_transform(data[column].astype(str))\n",
    "    label_encoders[column] = label_encoder\n",
    "    data[column] = encoded_values\n",
    "with open('label_encoders.pkl', 'wb') as file:\n",
    "   pickle.dump(label_encoders, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "columns_to_plot = [\"Platform\", \"Year_of_Release\", \"Publisher\", \"NA_Sales\", \"EU_Sales\",\n",
    "                   \"JP_Sales\", \"Other_Sales\", \"Global_Sales\", \"Critic_Score\",\n",
    "                   \"Critic_Count\", \"User_Score\", \"User_Count\", \"Developer\", \"Rating\", \"Genre\"]\n",
    "\n",
    "num_columns = 4\n",
    "num_rows = (len(columns_to_plot) + num_columns - 1) // num_columns\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_columns, figsize=(15, 20))\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, column in enumerate(columns_to_plot):\n",
    "    color = plt.cm.Set1(i % 14)\n",
    "\n",
    "    stats.probplot(data[column], plot=axes[i], dist='norm', fit=True)\n",
    "    axes[i].set_title(column)\n",
    "    axes[i].set_xlabel(\"Theoretical Quantiles\")\n",
    "    axes[i].set_ylabel(\"Ordered Values\")\n",
    "\n",
    "for j in range(len(columns_to_plot), num_rows * num_columns):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create boxplots for each column\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(data=data)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Boxplot of Columns\")\n",
    "plt.xlabel(\"Columns\")\n",
    "plt.ylabel(\"Values\")\n",
    "plt.show()\n",
    "\n",
    "# Create scatter plots for each column\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(data=data)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Scatterplot of Columns\")\n",
    "plt.xlabel(\"Columns\")\n",
    "plt.ylabel(\"Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = data.corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True) \n",
    "plt.show()                            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>Critic_Count</th>\n",
       "      <th>User_Score</th>\n",
       "      <th>User_Count</th>\n",
       "      <th>Developer</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11075</td>\n",
       "      <td>26</td>\n",
       "      <td>2006</td>\n",
       "      <td>10</td>\n",
       "      <td>361</td>\n",
       "      <td>4136</td>\n",
       "      <td>2896</td>\n",
       "      <td>377</td>\n",
       "      <td>844</td>\n",
       "      <td>8253</td>\n",
       "      <td>76</td>\n",
       "      <td>51</td>\n",
       "      <td>80</td>\n",
       "      <td>322</td>\n",
       "      <td>1020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9389</td>\n",
       "      <td>11</td>\n",
       "      <td>1985</td>\n",
       "      <td>4</td>\n",
       "      <td>361</td>\n",
       "      <td>2908</td>\n",
       "      <td>358</td>\n",
       "      <td>681</td>\n",
       "      <td>77</td>\n",
       "      <td>4024</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>1573</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5613</td>\n",
       "      <td>26</td>\n",
       "      <td>2008</td>\n",
       "      <td>6</td>\n",
       "      <td>361</td>\n",
       "      <td>1568</td>\n",
       "      <td>1276</td>\n",
       "      <td>379</td>\n",
       "      <td>329</td>\n",
       "      <td>3552</td>\n",
       "      <td>82</td>\n",
       "      <td>73</td>\n",
       "      <td>83</td>\n",
       "      <td>709</td>\n",
       "      <td>1020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11077</td>\n",
       "      <td>26</td>\n",
       "      <td>2009</td>\n",
       "      <td>10</td>\n",
       "      <td>361</td>\n",
       "      <td>1561</td>\n",
       "      <td>1093</td>\n",
       "      <td>328</td>\n",
       "      <td>295</td>\n",
       "      <td>3277</td>\n",
       "      <td>80</td>\n",
       "      <td>73</td>\n",
       "      <td>80</td>\n",
       "      <td>192</td>\n",
       "      <td>1020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7392</td>\n",
       "      <td>5</td>\n",
       "      <td>1996</td>\n",
       "      <td>7</td>\n",
       "      <td>361</td>\n",
       "      <td>1127</td>\n",
       "      <td>889</td>\n",
       "      <td>1022</td>\n",
       "      <td>100</td>\n",
       "      <td>3137</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>1573</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16714</th>\n",
       "      <td>8343</td>\n",
       "      <td>17</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>504</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1573</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16715</th>\n",
       "      <td>5160</td>\n",
       "      <td>28</td>\n",
       "      <td>2006</td>\n",
       "      <td>10</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>1573</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16716</th>\n",
       "      <td>3890</td>\n",
       "      <td>20</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>233</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1573</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16717</th>\n",
       "      <td>9028</td>\n",
       "      <td>6</td>\n",
       "      <td>2003</td>\n",
       "      <td>4</td>\n",
       "      <td>550</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>1573</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16718</th>\n",
       "      <td>11120</td>\n",
       "      <td>20</td>\n",
       "      <td>2016</td>\n",
       "      <td>9</td>\n",
       "      <td>504</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1573</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16717 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name  Platform  Year_of_Release  Genre  Publisher  NA_Sales  EU_Sales  \\\n",
       "0      11075        26             2006     10        361      4136      2896   \n",
       "1       9389        11             1985      4        361      2908       358   \n",
       "2       5613        26             2008      6        361      1568      1276   \n",
       "3      11077        26             2009     10        361      1561      1093   \n",
       "4       7392         5             1996      7        361      1127       889   \n",
       "...      ...       ...              ...    ...        ...       ...       ...   \n",
       "16714   8343        17             2016      0        504         0         0   \n",
       "16715   5160        28             2006     10         91         0         1   \n",
       "16716   3890        20             2016      1        233         0         0   \n",
       "16717   9028         6             2003      4        550         1         0   \n",
       "16718  11120        20             2016      9        504         0         0   \n",
       "\n",
       "       JP_Sales  Other_Sales  Global_Sales  Critic_Score  Critic_Count  \\\n",
       "0           377          844          8253            76            51   \n",
       "1           681           77          4024            73             1   \n",
       "2           379          329          3552            82            73   \n",
       "3           328          295          3277            80            73   \n",
       "4          1022          100          3137            91             1   \n",
       "...         ...          ...           ...           ...           ...   \n",
       "16714         1            0             1            78             1   \n",
       "16715         0            0             1            67             1   \n",
       "16716         1            0             1            78             1   \n",
       "16717         0            0             1            77             1   \n",
       "16718         1            0             1            78             1   \n",
       "\n",
       "       User_Score  User_Count  Developer  Rating  \n",
       "0              80         322       1020       1  \n",
       "1              59           1       1573       2  \n",
       "2              83         709       1020       1  \n",
       "3              80         192       1020       1  \n",
       "4              84           1       1573       2  \n",
       "...           ...         ...        ...     ...  \n",
       "16714          75           1       1573       7  \n",
       "16715          78           1       1573       1  \n",
       "16716          75           1       1573       7  \n",
       "16717          74           1       1573       2  \n",
       "16718          75           1       1573       2  \n",
       "\n",
       "[16717 rows x 16 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Genre', axis=1)\n",
    "y = data['Genre']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_standard = scaler.fit_transform(X_train)\n",
    "X_test_standard = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_robust = scaler.fit_transform(X_train)\n",
    "X_test_robust = scaler.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  normal probability plot (Q-Q plot) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier()\n",
    "#max_depth= None, min_samples_leaf= 1, min_samples_split=2, n_estimators= 300\n",
    "rf_classifier.fit(X_train,y=y_train)\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(f'MAE: {mean_absolute_error(y_test,y_pred)}')\n",
    "\n",
    "with open('random_forest_model.pkl', 'wb') as f:\n",
    "    pickle.dump(rf_classifier, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "rf = RandomForestClassifier()\n",
    "param_grid = {\n",
    "    'n_estimators': randint(100, 1000),  \n",
    "    'max_depth': randint(5, 20),         \n",
    "    'min_samples_split': randint(2, 10),  \n",
    "    'min_samples_leaf': randint(1, 10),  \n",
    "    'max_features': ['sqrt', 'log2']      \n",
    "}\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_grid, n_iter=10, cv=5)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "random_best_params = random_search.best_params_\n",
    "random_best_score = random_search.best_score_\n",
    "\n",
    "print(random_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_rf_classifier = RandomForestClassifier(**random_best_params)\n",
    "random_rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred_random = random_rf_classifier.predict(X_test)\n",
    "print('Accuracy Random Search: ',accuracy_score(y_test, y_pred_random))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC()\n",
    "svm.fit(X_train,y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(f'MAE: {mean_absolute_error(y_test,y_pred)}')\n",
    "\n",
    "with open('svm_model.pkl', 'wb') as f:\n",
    "    pickle.dump(svm, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': [0.1, 1, 10]\n",
    "}\n",
    "svm_classifier = SVC()\n",
    "grid_search = GridSearchCV(svm_classifier, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "svm = SVC(**best_params)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = svm.predict(X_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('Accuracy: ',accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lr = X\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_lr, y, test_size=0.2, random_state=420)\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "st_x= StandardScaler()  \n",
    "X_train= st_x.fit_transform(X_train)  \n",
    "X_test= st_x.transform(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(f'MAE: {mean_absolute_error(y_test,y_pred)}')\n",
    "\n",
    "with open('logistic_regression_model.pkl', 'wb') as f:\n",
    "    pickle.dump(lr, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear', 'saga']\n",
    "}\n",
    "\n",
    "logistic_classifier = LogisticRegression()\n",
    "\n",
    "grid_search = GridSearchCV(logistic_classifier, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_logistic_classifier = LogisticRegression(**best_params)\n",
    "best_logistic_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_logistic_classifier.predict(X_test)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf = RandomForestClassifier(max_depth= None, min_samples_leaf= 1, min_samples_split=2, n_estimators= 300)\n",
    "lr = LogisticRegression(C= 10, penalty= 'l2',solver= 'liblinear')\n",
    "svc = SVC(C= 10, gamma= 0.1, kernel= 'rbf')\n",
    "\n",
    "\n",
    "\n",
    "voting_classifier = VotingClassifier(\n",
    "    estimators=[('svc', svc), ('rf', rf), ('lr', lr)],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "voting_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = voting_classifier.predict(X_test)\n",
    "y_pred = voting_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(f'MAE: {mean_absolute_error(y_test,y_pred)}')\n",
    "\n",
    "with open('voting_classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(voting_classifier, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "rf = RandomForestClassifier(max_depth= None, min_samples_leaf= 1, min_samples_split=2, n_estimators= 300)\n",
    "lr = LogisticRegression(C= 10, penalty= 'l2',solver= 'liblinear',max_iter=1000)\n",
    "svc = SVC(C= 10, gamma= 0.1, kernel= 'rbf',max_iter=1000)\n",
    "fnn = MLPClassifier(hidden_layer_sizes=(256,), activation='relu', max_iter=1000)\n",
    "\n",
    "stacking_classifier = StackingClassifier(\n",
    "    estimators=[('svc', svc), ('rf', rf), ('lr', lr)],\n",
    "    final_estimator=fnn\n",
    ")\n",
    "\n",
    "stacking_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = stacking_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "with open('stacking_model.pkl', 'wb') as f:\n",
    "    pickle.dump(stacking_classifier, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saját modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "209/209 [==============================] - 3s 10ms/step - loss: 2.5146 - accuracy: 0.1384 - val_loss: 2.4394 - val_accuracy: 0.1941\n",
      "Epoch 2/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 2.4502 - accuracy: 0.1717 - val_loss: 2.3867 - val_accuracy: 0.1977\n",
      "Epoch 3/100\n",
      "209/209 [==============================] - 2s 9ms/step - loss: 2.3906 - accuracy: 0.1875 - val_loss: 2.3130 - val_accuracy: 0.1971\n",
      "Epoch 4/100\n",
      "209/209 [==============================] - 2s 9ms/step - loss: 2.3321 - accuracy: 0.2021 - val_loss: 2.2524 - val_accuracy: 0.2401\n",
      "Epoch 5/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 2.2895 - accuracy: 0.2210 - val_loss: 2.2012 - val_accuracy: 0.2670\n",
      "Epoch 6/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 2.2442 - accuracy: 0.2364 - val_loss: 2.1537 - val_accuracy: 0.2736\n",
      "Epoch 7/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 2.2077 - accuracy: 0.2483 - val_loss: 2.1198 - val_accuracy: 0.2823\n",
      "Epoch 8/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 2.1852 - accuracy: 0.2560 - val_loss: 2.0835 - val_accuracy: 0.2907\n",
      "Epoch 9/100\n",
      "209/209 [==============================] - 2s 9ms/step - loss: 2.1576 - accuracy: 0.2661 - val_loss: 2.0624 - val_accuracy: 0.2901\n",
      "Epoch 10/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 2.1383 - accuracy: 0.2759 - val_loss: 2.0411 - val_accuracy: 0.2981\n",
      "Epoch 11/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 2.1165 - accuracy: 0.2768 - val_loss: 2.0114 - val_accuracy: 0.3158\n",
      "Epoch 12/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 2.0897 - accuracy: 0.2877 - val_loss: 1.9802 - val_accuracy: 0.3245\n",
      "Epoch 13/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 2.0696 - accuracy: 0.2912 - val_loss: 1.9640 - val_accuracy: 0.3400\n",
      "Epoch 14/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 2.0546 - accuracy: 0.2954 - val_loss: 1.9422 - val_accuracy: 0.3499\n",
      "Epoch 15/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 2.0289 - accuracy: 0.3063 - val_loss: 1.9215 - val_accuracy: 0.3508\n",
      "Epoch 16/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 2.0175 - accuracy: 0.3126 - val_loss: 1.8977 - val_accuracy: 0.3514\n",
      "Epoch 17/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 2.0048 - accuracy: 0.3196 - val_loss: 1.8867 - val_accuracy: 0.3538\n",
      "Epoch 18/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.9890 - accuracy: 0.3183 - val_loss: 1.8712 - val_accuracy: 0.3556\n",
      "Epoch 19/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.9827 - accuracy: 0.3274 - val_loss: 1.8653 - val_accuracy: 0.3589\n",
      "Epoch 20/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.9687 - accuracy: 0.3248 - val_loss: 1.8417 - val_accuracy: 0.3615\n",
      "Epoch 21/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.9538 - accuracy: 0.3257 - val_loss: 1.8437 - val_accuracy: 0.3615\n",
      "Epoch 22/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.9309 - accuracy: 0.3354 - val_loss: 1.8272 - val_accuracy: 0.3633\n",
      "Epoch 23/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.9247 - accuracy: 0.3330 - val_loss: 1.8102 - val_accuracy: 0.3657\n",
      "Epoch 24/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.9175 - accuracy: 0.3415 - val_loss: 1.8075 - val_accuracy: 0.3660\n",
      "Epoch 25/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.9045 - accuracy: 0.3402 - val_loss: 1.7908 - val_accuracy: 0.3654\n",
      "Epoch 26/100\n",
      "209/209 [==============================] - 2s 9ms/step - loss: 1.9018 - accuracy: 0.3475 - val_loss: 1.7872 - val_accuracy: 0.3654\n",
      "Epoch 27/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.8856 - accuracy: 0.3449 - val_loss: 1.7777 - val_accuracy: 0.3693\n",
      "Epoch 28/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.8728 - accuracy: 0.3442 - val_loss: 1.7688 - val_accuracy: 0.3732\n",
      "Epoch 29/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.8754 - accuracy: 0.3497 - val_loss: 1.7685 - val_accuracy: 0.3720\n",
      "Epoch 30/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.8568 - accuracy: 0.3467 - val_loss: 1.7546 - val_accuracy: 0.3765\n",
      "Epoch 31/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.8557 - accuracy: 0.3493 - val_loss: 1.7478 - val_accuracy: 0.3714\n",
      "Epoch 32/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.8505 - accuracy: 0.3497 - val_loss: 1.7384 - val_accuracy: 0.3732\n",
      "Epoch 33/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.8312 - accuracy: 0.3563 - val_loss: 1.7371 - val_accuracy: 0.3747\n",
      "Epoch 34/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.8374 - accuracy: 0.3550 - val_loss: 1.7309 - val_accuracy: 0.3735\n",
      "Epoch 35/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.8221 - accuracy: 0.3627 - val_loss: 1.7250 - val_accuracy: 0.3762\n",
      "Epoch 36/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.8217 - accuracy: 0.3604 - val_loss: 1.7200 - val_accuracy: 0.3747\n",
      "Epoch 37/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.8160 - accuracy: 0.3589 - val_loss: 1.7180 - val_accuracy: 0.3789\n",
      "Epoch 38/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.8087 - accuracy: 0.3632 - val_loss: 1.7124 - val_accuracy: 0.3810\n",
      "Epoch 39/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.8102 - accuracy: 0.3603 - val_loss: 1.7066 - val_accuracy: 0.3786\n",
      "Epoch 40/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.8026 - accuracy: 0.3595 - val_loss: 1.7049 - val_accuracy: 0.3810\n",
      "Epoch 41/100\n",
      "209/209 [==============================] - 2s 9ms/step - loss: 1.7979 - accuracy: 0.3632 - val_loss: 1.6982 - val_accuracy: 0.3840\n",
      "Epoch 42/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.7834 - accuracy: 0.3665 - val_loss: 1.6927 - val_accuracy: 0.3858\n",
      "Epoch 43/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.7870 - accuracy: 0.3700 - val_loss: 1.6898 - val_accuracy: 0.3888\n",
      "Epoch 44/100\n",
      "209/209 [==============================] - 2s 9ms/step - loss: 1.7767 - accuracy: 0.3680 - val_loss: 1.6863 - val_accuracy: 0.3935\n",
      "Epoch 45/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.7761 - accuracy: 0.3696 - val_loss: 1.6907 - val_accuracy: 0.3900\n",
      "Epoch 46/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.7698 - accuracy: 0.3711 - val_loss: 1.6806 - val_accuracy: 0.3932\n",
      "Epoch 47/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.7695 - accuracy: 0.3728 - val_loss: 1.6783 - val_accuracy: 0.3950\n",
      "Epoch 48/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.7707 - accuracy: 0.3746 - val_loss: 1.6779 - val_accuracy: 0.4019\n",
      "Epoch 49/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.7655 - accuracy: 0.3761 - val_loss: 1.6754 - val_accuracy: 0.3989\n",
      "Epoch 50/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.7562 - accuracy: 0.3747 - val_loss: 1.6704 - val_accuracy: 0.4001\n",
      "Epoch 51/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.7508 - accuracy: 0.3722 - val_loss: 1.6643 - val_accuracy: 0.4004\n",
      "Epoch 52/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.7564 - accuracy: 0.3749 - val_loss: 1.6653 - val_accuracy: 0.4043\n",
      "Epoch 53/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.7453 - accuracy: 0.3792 - val_loss: 1.6642 - val_accuracy: 0.4028\n",
      "Epoch 54/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.7341 - accuracy: 0.3772 - val_loss: 1.6615 - val_accuracy: 0.4010\n",
      "Epoch 55/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.7423 - accuracy: 0.3789 - val_loss: 1.6621 - val_accuracy: 0.4052\n",
      "Epoch 56/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.7425 - accuracy: 0.3832 - val_loss: 1.6564 - val_accuracy: 0.4115\n",
      "Epoch 57/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.7279 - accuracy: 0.3870 - val_loss: 1.6521 - val_accuracy: 0.4103\n",
      "Epoch 58/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.7187 - accuracy: 0.3891 - val_loss: 1.6528 - val_accuracy: 0.4130\n",
      "Epoch 59/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.7258 - accuracy: 0.3847 - val_loss: 1.6491 - val_accuracy: 0.4106\n",
      "Epoch 60/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.7222 - accuracy: 0.3855 - val_loss: 1.6485 - val_accuracy: 0.4094\n",
      "Epoch 61/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.7203 - accuracy: 0.3851 - val_loss: 1.6504 - val_accuracy: 0.4130\n",
      "Epoch 62/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.7115 - accuracy: 0.3917 - val_loss: 1.6453 - val_accuracy: 0.4118\n",
      "Epoch 63/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.7142 - accuracy: 0.3895 - val_loss: 1.6436 - val_accuracy: 0.4166\n",
      "Epoch 64/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.7016 - accuracy: 0.3926 - val_loss: 1.6445 - val_accuracy: 0.4121\n",
      "Epoch 65/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.7085 - accuracy: 0.3896 - val_loss: 1.6394 - val_accuracy: 0.4136\n",
      "Epoch 66/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.7010 - accuracy: 0.3955 - val_loss: 1.6349 - val_accuracy: 0.4163\n",
      "Epoch 67/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.6980 - accuracy: 0.3968 - val_loss: 1.6399 - val_accuracy: 0.4154\n",
      "Epoch 68/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.6858 - accuracy: 0.3967 - val_loss: 1.6326 - val_accuracy: 0.4157\n",
      "Epoch 69/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.6920 - accuracy: 0.3991 - val_loss: 1.6343 - val_accuracy: 0.4154\n",
      "Epoch 70/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.6827 - accuracy: 0.3974 - val_loss: 1.6265 - val_accuracy: 0.4184\n",
      "Epoch 71/100\n",
      "209/209 [==============================] - 2s 9ms/step - loss: 1.6867 - accuracy: 0.3953 - val_loss: 1.6307 - val_accuracy: 0.4193\n",
      "Epoch 72/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.6795 - accuracy: 0.4016 - val_loss: 1.6280 - val_accuracy: 0.4175\n",
      "Epoch 73/100\n",
      "209/209 [==============================] - 2s 9ms/step - loss: 1.6832 - accuracy: 0.3999 - val_loss: 1.6217 - val_accuracy: 0.4190\n",
      "Epoch 74/100\n",
      "209/209 [==============================] - 2s 9ms/step - loss: 1.6829 - accuracy: 0.3984 - val_loss: 1.6235 - val_accuracy: 0.4217\n",
      "Epoch 75/100\n",
      "209/209 [==============================] - 2s 9ms/step - loss: 1.6695 - accuracy: 0.4007 - val_loss: 1.6233 - val_accuracy: 0.4196\n",
      "Epoch 76/100\n",
      "209/209 [==============================] - 2s 9ms/step - loss: 1.6696 - accuracy: 0.4070 - val_loss: 1.6238 - val_accuracy: 0.4205\n",
      "Epoch 77/100\n",
      "209/209 [==============================] - 2s 9ms/step - loss: 1.6597 - accuracy: 0.4043 - val_loss: 1.6226 - val_accuracy: 0.4202\n",
      "Epoch 78/100\n",
      "209/209 [==============================] - 2s 9ms/step - loss: 1.6637 - accuracy: 0.4069 - val_loss: 1.6170 - val_accuracy: 0.4208\n",
      "Epoch 79/100\n",
      "209/209 [==============================] - 2s 9ms/step - loss: 1.6545 - accuracy: 0.4073 - val_loss: 1.6182 - val_accuracy: 0.4202\n",
      "Epoch 80/100\n",
      "209/209 [==============================] - 2s 9ms/step - loss: 1.6553 - accuracy: 0.4036 - val_loss: 1.6218 - val_accuracy: 0.4199\n",
      "Epoch 81/100\n",
      "209/209 [==============================] - 2s 9ms/step - loss: 1.6558 - accuracy: 0.4067 - val_loss: 1.6165 - val_accuracy: 0.4208\n",
      "Epoch 82/100\n",
      "209/209 [==============================] - 2s 9ms/step - loss: 1.6582 - accuracy: 0.4042 - val_loss: 1.6171 - val_accuracy: 0.4219\n",
      "Epoch 83/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.6468 - accuracy: 0.4111 - val_loss: 1.6149 - val_accuracy: 0.4222\n",
      "Epoch 84/100\n",
      "209/209 [==============================] - 2s 9ms/step - loss: 1.6440 - accuracy: 0.4091 - val_loss: 1.6121 - val_accuracy: 0.4214\n",
      "Epoch 85/100\n",
      "209/209 [==============================] - 2s 9ms/step - loss: 1.6489 - accuracy: 0.4139 - val_loss: 1.6101 - val_accuracy: 0.4228\n",
      "Epoch 86/100\n",
      "209/209 [==============================] - 2s 9ms/step - loss: 1.6472 - accuracy: 0.4122 - val_loss: 1.6080 - val_accuracy: 0.4240\n",
      "Epoch 87/100\n",
      "209/209 [==============================] - 2s 9ms/step - loss: 1.6395 - accuracy: 0.4155 - val_loss: 1.6053 - val_accuracy: 0.4240\n",
      "Epoch 88/100\n",
      "209/209 [==============================] - 2s 9ms/step - loss: 1.6376 - accuracy: 0.4128 - val_loss: 1.6072 - val_accuracy: 0.4261\n",
      "Epoch 89/100\n",
      "209/209 [==============================] - 2s 9ms/step - loss: 1.6379 - accuracy: 0.4155 - val_loss: 1.6090 - val_accuracy: 0.4234\n",
      "Epoch 90/100\n",
      "209/209 [==============================] - 2s 9ms/step - loss: 1.6356 - accuracy: 0.4170 - val_loss: 1.6054 - val_accuracy: 0.4270\n",
      "Epoch 91/100\n",
      "209/209 [==============================] - 2s 9ms/step - loss: 1.6301 - accuracy: 0.4205 - val_loss: 1.6010 - val_accuracy: 0.4249\n",
      "Epoch 92/100\n",
      "209/209 [==============================] - 2s 9ms/step - loss: 1.6259 - accuracy: 0.4174 - val_loss: 1.6013 - val_accuracy: 0.4264\n",
      "Epoch 93/100\n",
      "209/209 [==============================] - 2s 9ms/step - loss: 1.6164 - accuracy: 0.4197 - val_loss: 1.5936 - val_accuracy: 0.4264\n",
      "Epoch 94/100\n",
      "209/209 [==============================] - 2s 9ms/step - loss: 1.6204 - accuracy: 0.4149 - val_loss: 1.6007 - val_accuracy: 0.4312\n",
      "Epoch 95/100\n",
      "209/209 [==============================] - 2s 9ms/step - loss: 1.6175 - accuracy: 0.4230 - val_loss: 1.5977 - val_accuracy: 0.4279\n",
      "Epoch 96/100\n",
      "209/209 [==============================] - 2s 9ms/step - loss: 1.6185 - accuracy: 0.4216 - val_loss: 1.5994 - val_accuracy: 0.4279\n",
      "Epoch 97/100\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 1.6140 - accuracy: 0.4173 - val_loss: 1.5986 - val_accuracy: 0.4282\n",
      "Epoch 98/100\n",
      "209/209 [==============================] - 2s 9ms/step - loss: 1.6145 - accuracy: 0.4219 - val_loss: 1.5965 - val_accuracy: 0.4318\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 1.5965 - accuracy: 0.4318\n",
      "Test Loss: 1.596475601196289\n",
      "Test Accuracy: 0.4318181872367859\n"
     ]
    }
   ],
   "source": [
    "X_train_=X_train_robust\n",
    "X_test_=X_test_robust\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu', input_shape=(X_train_.shape[1],)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(len(y.unique()), activation='softmax'))\n",
    "\n",
    "learning_rate = 0.0001 \n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(patience=5)\n",
    "history = model.fit(X_train_, y_train, validation_data=(X_test_, y_test),\n",
    "                    batch_size=64, epochs=100, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test_, y_test)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
